{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12034a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################## Import libraries\n",
    "from __future__ import print_function\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from scipy.io import savemat\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "import numpy as np\n",
    "import pickle\n",
    "from models.skip_dropout_LatestOrder import skip\n",
    "import torch\n",
    "from torch import optim\n",
    "import scipy.io\n",
    "import time\n",
    "\n",
    "########################################################## from utils.inpainting_utils import *\n",
    "from utils.common_utils import *\n",
    "from utils.my_utils import *\n",
    "from utils.fftc import * # ra: added the pytorch fft routine from fastmri\n",
    "\n",
    "import os# os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "\n",
    "torch.backends.cudnn.enabled = True\n",
    "torch.backends.cudnn.benchmark =True\n",
    "dtype = torch.cuda.FloatTensor\n",
    "\n",
    "PLOT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f1d2215",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.cuda.device_count()) # restart shell if it doesnt show 2\n",
    "device = 0\n",
    "torch.cuda.set_device(device) # 0/1\n",
    "print(torch.cuda.current_device())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4958d7de",
   "metadata": {},
   "source": [
    "## Select parameters and dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a44407da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select parameetrs:\n",
    "R=4\n",
    "FS=1\n",
    "nt= 32 # ablation\n",
    "# choose num of frames to run\n",
    "\n",
    "# select dataset:\n",
    "# Choose from \"{\"with_lesion\", \"without_lesion\"}\"\n",
    "folder = \"with_lesion\" # 'with_lesion' # 'without_lesion'\n",
    "patient = \"male_pt77\" # choose from: {'female_pt71', 'male_pt77', 'male_pt80'}\n",
    "path = \"../data/MRXCAT/\"\n",
    "\n",
    "data_path = path+folder+\"/\"+patient+\"/\"\n",
    "if FS:\n",
    "    data_path_r = data_path + \"R%d/\"%R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f6ca2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## display\n",
    "gm = [1, 1, 1] # gamma correction for display\n",
    "g=1\n",
    "mps = [plt.cm.Greys_r, 'gray']\n",
    "\n",
    "epsilon = 1e-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3cc38ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read US data:\n",
    "# from set0\n",
    "ksp = np.load(data_path_r+\"yu\" +\"_R_%f\"%R+\".npy\")\n",
    "print(ksp.shape, ksp.dtype)\n",
    "(N,Nc,Nx,Ny) = np.shape(ksp)\n",
    "n = (Nx, Ny)\n",
    "\n",
    "\n",
    "# ksp_c = real_plus_imag_to_complex_4d(ksp_n)\n",
    "msk = np.load(data_path_r+\"mask_R_%f\"%R+\".npy\")\n",
    "print(msk.shape, msk.dtype)\n",
    "\n",
    "\n",
    "# from set1:\n",
    "maps = np.load(data_path+\"sen_maps\"+\".npy\")\n",
    "print(maps.shape, maps.dtype)\n",
    "\n",
    "\n",
    "if FS:\n",
    "    img = np.load(data_path+\"xRef_N_%d\"%(N)+\".npy\")\n",
    "    print(img.shape, img.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a69a28b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ku = complex_to_real_plus_imag_4d(ksp)\n",
    "if FS:\n",
    "    # samp = np.transpose(msk, (1,3,2,0))\n",
    "    m = complex_to_real_plus_imag_3d(img)\n",
    "    print(m.shape) # (2*N, RO, PE)\n",
    "\n",
    "\n",
    "# else:\n",
    "samp = msk\n",
    "sen = complex_to_real_plus_imag_4d(np.expand_dims(np.transpose(maps,(2,0,1)),axis=0))\n",
    "# sen = complex_to_real_plus_imag_4d(maps)\n",
    "\n",
    "# print(\"\\ndata sizes going to DISCUS\")\n",
    "# print(ku.shape) # (2*N, CH, RO, PE)\n",
    "# print(samp.shape) # (N, CH, RO, PE)\n",
    "# print(sen.shape) # (2, CH, RO, PE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc0cf93",
   "metadata": {},
   "source": [
    "## CS-L1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff8489f",
   "metadata": {},
   "outputs": [],
   "source": [
    "PLOT_CS = 0\n",
    "show_every_CS = 10 \n",
    "\n",
    "\n",
    "mu = 1e-1 # lagrangian parameter\n",
    "nIter = np.array([500, 5]) # 300 # outer and inner iterations\n",
    "ss = 0.7\n",
    "if R==2:\n",
    "    ss = 0.4 #0.5# 0.4 # step size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "282ed50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################## CS Recon\n",
    "# get the start time\n",
    "# st = time.time()\n",
    "\n",
    "tau=0.001\n",
    "\n",
    "csRe=1\n",
    "\n",
    "ar = 0.75 # aspect ratio for plotting xAbs\n",
    "\n",
    "if csRe==1:\n",
    "  # Running ADMM L2-L1\n",
    "\n",
    "  xCS = np.zeros((2*N,n[0],n[1]))\n",
    "  Sc = ScN\n",
    "\n",
    "  # xCSAbs = np.zeros((N,n[0],n[1]))\n",
    "  # if FS:\n",
    "  #   nmse = np.zeros([N,1])\n",
    "  #   ssm = np.zeros([N,1])\n",
    "  #   psn = np.zeros([N,1])\n",
    "  #   xAbs = np.zeros((N,n[0],n[1]))\n",
    "  #   errMap = np.zeros((2*N,n[0],n[1]))\n",
    "\n",
    "  # xCSF = np.zeros((2*N,n[0],n[1]))\n",
    "  # xCSFAbs = np.zeros((N,n[0],n[1]))\n",
    "  # # yAbs = np.zeros((N,n[0],n[1]))\n",
    "  # # errFMap = np.zeros((2*N,n[0],n[1]))\n",
    "\n",
    "\n",
    "# CS-L1: individual recon (frame by frame); no common support bw frames\n",
    "  for i in range(N): \n",
    "    loss = np.zeros(nIter[0]) # track training loss to see stability of learning\n",
    "    psnr_iter = np.zeros(nIter[0]) # track psnr to find stopping criteria (number of iter.s)\n",
    "\n",
    "    print('\\nSlice: %2d' %(i+1), 'out of %2d' %N)\n",
    "    x0 = (np.zeros(n)).astype(complex)\n",
    "#     print(yuN.shape)\n",
    "#     print(mskN.shape)\n",
    "    y0 = yuN[2*i,:,:,:] + 1j*yuN[2*i+1,:,:,:]\n",
    "    msk0 = mskN[i,:,:,:]\n",
    "    # Sc = ScN[i,:,:,:]\n",
    "    \n",
    "\n",
    "    # ADMM\n",
    "    #xTmp = admm_pmri_l1(x0, y0, msk0, ScN, nIter, ss, mu, tau) ## returns reconstructed x only (no weights i.e., d, b, )\n",
    "    # x = x0\n",
    "    # y = y0\n",
    "\n",
    "    B = 4 # wavelet bands\n",
    "    u = pAt(y0, msk0, Sc) # starts with ZF-image\n",
    "    # print(u.shape)\n",
    "    d = np.zeros((B,x0.shape[0],x0.shape[1])).astype(complex)\n",
    "    b = np.zeros((B,x0.shape[0],x0.shape[1])).astype(complex)\n",
    "\n",
    "    # ii=0 # iterations\n",
    "\n",
    "    for l in range(nIter[0]): # outer iter\n",
    "\n",
    "\n",
    "      for j in range(nIter[1]): # inner iter\n",
    "\n",
    "        lossA = pA(u, msk0, Sc) - y0 # Data consistency\n",
    "        gradA = pAt(lossA, msk0, Sc)\n",
    "\n",
    "        lossW = swt2_haar(u) - d + b # wavelet reg.\n",
    "        gradW = mu * iswt2_haar(lossW) \n",
    "\n",
    "        # loss[l] = np.sum(np.abs(lossA)**2) + mu*np.sum(np.abs(lossW))\n",
    "\n",
    "        u = u - ss * (gradA + gradW) # grad. update\n",
    "\n",
    "        # ii = ii + 1\n",
    "\n",
    "\n",
    "\n",
    "        # xAbs[i:i+1,:,:] = np.sqrt((xN[i*2,:,:])**2 + (xN[i*2+1,:,:])**2)\n",
    "        # errMap[i*2:(i+1)*2,:,:] = xN[i*2:(i+1)*2,:,:]-xCS[i*2:(i+1)*2,:,:]\n",
    "\n",
    "        # nmse[i] =  np.mean((xN[i*2:(i+1)*2,:,:]-xCS[i*2:(i+1)*2,:,:])**2) / np.mean((xN[i*2:(i+1)*2,:,:])**2)\n",
    "        # ssm[i] = ssim(xCSAbs[i,:,:], xAbs[i,:,:], data_range = xCSAbs[i,:,:].max() - xCSAbs[i,:,:].min()) # xCSL1Abs[i:i+1,:,:].max() - xCSL1Abs[i:i+1,:,:].min()\n",
    "        \n",
    "        # print('\\nNMSE : %1.2f' %(10*np.log10(nmse[i])))\n",
    "        # print('SSIM : %1.2f' %(ssm[i]))\n",
    "\n",
    "\n",
    "      # recon weights learnt: d, b\n",
    "      d = st(swt2_haar(u) + b, tau/mu) \n",
    "      b = b + (swt2_haar(u) - d)\n",
    "      \n",
    "      loss[l] = np.sum(np.abs(lossA)**2) + mu*np.sum(np.abs(lossW))\n",
    "\n",
    "      # calc PSNR:\n",
    "      xHat_it = np.zeros((2,n[0],n[1]))\n",
    "      if FS:\n",
    "        xHat_itAbs = np.zeros((1, n[0],n[1]))\n",
    "        x_itAbs = np.zeros((1, n[0],n[1]))\n",
    "      xHat_it[0,:,:]  = np.real(u)\n",
    "      xHat_it[1,:,:] = np.imag(u)\n",
    "      xHat_itAbs = np.sqrt((xHat_it[0,:,:])**2 + (xHat_it[1,:,:])**2)\n",
    "      x_itAbs = np.sqrt((xN[i*2,:,:])**2 + (xN[i*2+1,:,:])**2)\n",
    "      psn_it = psnr(x_itAbs, xHat_itAbs, data_range = xHat_itAbs.max() - xHat_itAbs.min()) # xCSL1Abs[i:i+1,:,:].max() - xCSL1Abs[i:i+1,:,:].min()\n",
    "      psnr_iter[l] = psn_it\n",
    "    \n",
    "      if PLOT_CS:\n",
    "\n",
    "\n",
    "        if  l==0 or (l+1) % show_every_CS ==0:\n",
    "          print('Iteration: %2d ' %(l+1))\n",
    "\n",
    "          xHat_it = np.zeros((2,n[0],n[1]))\n",
    "          if FS:\n",
    "            xHat_itAbs = np.zeros((1, n[0],n[1]))\n",
    "            x_itAbs = np.zeros((1, n[0],n[1]))\n",
    "\n",
    "                # recon image: u\n",
    "          xHat_it[0,:,:]  = np.real(u)\n",
    "          xHat_it[1,:,:] = np.imag(u)\n",
    "          xHat_itAbs = np.sqrt((xHat_it[0,:,:])**2 + (xHat_it[1,:,:])**2)\n",
    "          if FS:\n",
    "            x_itAbs = np.sqrt((xN[i*2,:,:])**2 + (xN[i*2+1,:,:])**2)\n",
    "            nmse_it =  np.mean((xN[i*2:(i+1)*2,:,:]-xHat_it)**2) / np.mean((xN[i*2:(i+1)*2,:,:])**2)\n",
    "            ssm_it = ssim(xHat_itAbs, x_itAbs, data_range = xHat_itAbs.max() - xHat_itAbs.min()) # xCSL1Abs[i:i+1,:,:].max() - xCSL1Abs[i:i+1,:,:].min()\n",
    "            psn_it = psnr(x_itAbs, xHat_itAbs, data_range = xHat_itAbs.max() - xHat_itAbs.min()) # xCSL1Abs[i:i+1,:,:].max() - xCSL1Abs[i:i+1,:,:].min()\n",
    "            \n",
    "            # nmse_iter[l] = 10*np.log10(nmse_it)\n",
    "\n",
    "            print('\\nNMSE : %1.2f' %(10*np.log10(nmse_it)))\n",
    "            print('SSIM : %1.2f' %(ssm_it))\n",
    "            print('PSNR : %1.2f' %(psn_it))\n",
    "            fig = plt.figure(figsize=(6,5),facecolor='white', edgecolor=None)\n",
    "            plt.imshow(np.reshape(np.transpose(np.concatenate((np.expand_dims(xHat_itAbs**g, axis=0), np.expand_dims(x_itAbs**g, axis=0)), axis=2),[1,0,2]), [n[0],n[1]*2]), cmap=plt.cm.Greys_r, aspect=(n[1]/n[0])/ar) # use a specific color map\n",
    "            plt.title(\"xHat_itAbs, x_itAbs\")\n",
    "            plt.show()\n",
    "          else:\n",
    "            fig = plt.figure(figsize=(6,5),facecolor='white', edgecolor=None)\n",
    "            plt.imshow(xHat_itAbs**g, cmap=plt.cm.Greys_r, aspect=(n[1]/n[0])/ar) # use a specific color map\n",
    "            plt.title(\"xHat_itAbs\")\n",
    "            plt.show()    \n",
    "\n",
    "      if i==N-1 and l==nIter[0]-1: # last outer iter.\n",
    "        fig = plt.figure(figsize=(16,5),facecolor='white', edgecolor=None)\n",
    "        plt.plot(np.log10(loss))\n",
    "        plt.xlabel(\"No. of iterations\")\n",
    "        plt.ylabel(\"Total loss\")\n",
    "        plt.show()\n",
    "\n",
    "        if FS:\n",
    "          fig = plt.figure(figsize=(16,5),facecolor='white', edgecolor=None)\n",
    "          plt.plot(psnr_iter)\n",
    "          plt.xlabel(\"No. of iterations\")\n",
    "          plt.ylabel(\"PSNR\")\n",
    "          plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #return u # recon image\n",
    "    # xTmp = u\n",
    "\n",
    "  \n",
    "\n",
    "    xCS[2*i,:,:]   = np.real(u)\n",
    "    xCS[2*i+1,:,:] = np.imag(u)\n",
    "    # xCSAbs[i:i+1,:,:] = np.sqrt((xCS[i*2,:,:])**2 + (xCS[i*2+1,:,:])**2)\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    # fTmp = np.fft.fftshift(np.fft.fft2(np.fft.ifftshift(xTmp, axes=(-2, -1)), axes=(-2, -1), norm='ortho'), axes=(-2, -1))\n",
    "    # xCSF[2*i,:,:]   = np.real(fTmp)\n",
    "    # xCSF[2*i+1,:,:] = np.imag(fTmp)\n",
    "    # xCSFAbs[i:i+1,:,:] = np.sqrt((xCSF[i*2,:,:])**2 + (xCSF[i*2+1,:,:])**2)\n",
    "    # yAbs[i:i+1,:,:] = np.sqrt((yN[i*2,:,:])**2 + (yN[i*2+1,:,:])**2)\n",
    "    # errFMap[i*2:(i+1)*2,:,:] = yN[i*2:(i+1)*2,:,:]-xCSF[i*2:(i+1)*2,:,:]\n",
    "\n",
    "  xCSAbs = takeMag(xCS)\n",
    "\n",
    "  if FS:\n",
    "    xAbs = takeMag(xN)\n",
    "    errMap = xN-xCS\n",
    "    nmse =  calc_nmse(real_plus_imag_to_complex_3d(xCS), real_plus_imag_to_complex_3d(xN))\n",
    "    # ssm[i] = ssim(xCSAbs[i,:,:], xAbs[i,:,:], data_range = xCSAbs[i,:,:].max() - xCSAbs[i,:,:].min()) # xCSL1Abs[i:i+1,:,:].max() - xCSL1Abs[i:i+1,:,:].min()\n",
    "    # psn[i] = psnr( xAbs[i,:,:], xCSAbs[i,:,:], data_range = xCSAbs[i,:,:].max() - xCSAbs[i,:,:].min()) # xCSL1Abs[i:i+1,:,:].max() - xCSL1Abs[i:i+1,:,:].min()\n",
    "    # print('\\nNMSE : %1.2f' %(10*np.log10(nmse[i])))\n",
    "    # print('SSIM : %1.2f' %(ssm[i]))\n",
    "    # print('PSNR : %1.2f' %(psn[i]))\n",
    "\n",
    "    \n",
    "  fig = plt.figure(figsize=(16,8),facecolor='white', edgecolor=None)\n",
    "  #plt.imshow(np.reshape(np.transpose(xCSAbs**0.9,[1,0,2]), [n[0],n[1]*N]), vmin=0, vmax=0.5*np.max(xCSAbs**0.9), cmap=plt.cm.Greys_r, aspect=(n[1]/n[0])/ar) # use a specific color map\n",
    "  plt.imshow(np.reshape(np.transpose(xCSAbs**g,[1,0,2]), [n[0],n[1]*N]), cmap=plt.cm.Greys_r) # use a specific color map\n",
    "  plt.title(\"xCSAbs\")\n",
    "  plt.show()\n",
    "    \n",
    "  if FS:\n",
    "    print('\\nMean nmse: %1.2f,' %(10*np.log10(np.mean(nmse))), 'nmse: ',', '.join('%1.2f' % (10*np.log10(nmse[j])) for j in range(len(nmse)))) \n",
    "    # print('Mean ssim: %1.3f,' %(np.mean(ssm)), 'ssim: ',', '.join('%1.3f' % (ssm[j]) for j in range(len(ssm)))) \n",
    "    # print('Mean psnr: %1.3f,' %(np.mean(psn)), 'psnr: ',', '.join('%1.3f' % (psn[j]) for j in range(len(psn)))) \n",
    "   \n",
    "    fig = plt.figure(figsize=(16,8),facecolor='white', edgecolor=None)\n",
    "    plt.imshow(np.reshape(np.transpose(xAbs**g,[1,0,2]), [n[0],n[1]*N]), cmap=mps[0]) # use a specific color map\n",
    "    plt.title(\"xAbs\")\n",
    "    plt.show()\n",
    "  #   fig = plt.figure(figsize=(16,8),facecolor='white', edgecolor=None)\n",
    "  #   plt.imshow(np.reshape(np.transpose(np.concatenate((xAbs[0:1,:,:]**0.99, xCSAbs[0:1,:,:]**0.99), axis=2),[1,0,2]), [n[0],n[1]*2]), cmap=plt.cm.Greys_r) # use a specific color map\n",
    "  #   plt.title(\"xAbs, xCSAbs\")  \n",
    "  #   plt.show()\n",
    "\n",
    "      \n",
    "    fig = plt.figure(figsize=(16,8),facecolor='white', edgecolor=None)\n",
    "    plt.imshow(np.reshape(np.transpose(takeMag(errMap),[1,0,2]), [n[0],n[1]*N]),vmin=0, vmax=(np.max(errMap)/5), cmap=plt.cm.Greys_r) # use a specific color map\n",
    "    plt.title(\"errxMap\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    " \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9ee914",
   "metadata": {},
   "outputs": [],
   "source": [
    "sv_CS=1\n",
    "CSresults_path=data_path_r\n",
    "string = \"\"\n",
    "if sv_CS==1: np.save(CSresults_path + string+'xHatCSL1_'+'N_%d' % N + '_R_%f'%R+ '.npy', xCS)\n",
    "if FS:\n",
    "    if sv_CS==1: np.save(CSresults_path + string+ 'xRefCSL1_'+'N_%d' % N +'.npy', xN)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0213ad39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3cd209e3",
   "metadata": {},
   "source": [
    "# DISCUS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2e516f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc6a33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_iter = 12000 # number of iterations\n",
    "show_every = 1000\n",
    "\n",
    "\n",
    "## tuning parameters...\n",
    "# code vectors init\n",
    "reg_sig0 = 0.01 #0.03 # noise regularization \n",
    "#code vector sparsity\n",
    "z_scale = 1\n",
    "\n",
    "\n",
    "# adam optimization\n",
    "WtD = 1*1e-6 # weight decay \n",
    "p=0 #0.01 # keep drop_out\n",
    "\n",
    "\n",
    "sv=0\n",
    "cf=30\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac05582",
   "metadata": {},
   "outputs": [],
   "source": [
    "## DISCUS Archit. Parameters:\n",
    "\n",
    "opt = 2 # select the flavor of the algorithm\n",
    "LSz = 128 # Number of channels in hidden layers\n",
    "NLy = 6 # number of layers\n",
    "Nm = 2**NLy # minimum matrix size for UNet # depends on giveb data matrix size\n",
    "# code accepts both even and odd sized matrix sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13581aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for DISCUS\n",
    "## Final pre-processed data:\n",
    "\n",
    "N=nt\n",
    "idx = np.random.randint(32, size=N) # random nt frames from total 32 available\n",
    "print(idx)\n",
    "\n",
    "#     yn = ynN\n",
    "yuN = complex_to_real_plus_imag_4d(real_plus_imag_to_complex_4d(ku)[idx,:,:,:])\n",
    "# yuN = ku[0:2*N, :,:,:] # DS kspace\n",
    "# mskN = samp[0:N, :,:,:]\n",
    "mskN = samp[idx, :,:,:]\n",
    "\n",
    "SN = sen\n",
    "ScN = np.transpose(maps, (2,0,1))\n",
    "\n",
    "print(yuN.shape) # (2*N, CH, RO, PE)\n",
    "print(mskN.shape) # (N, CH, RO, PE)\n",
    "print(SN.shape) # (2, CH, RO, PE)\n",
    "print(ScN.shape) # (CH, RO, PE)\n",
    "\n",
    "sen_msk = np.ones((n[0],n[1]))\n",
    "print(sen_msk.shape) # (RO, PE)\n",
    "\n",
    "if FS:\n",
    "    # xN  = m[0:2*N, :,:]*sen_msk # skip 1st frame # ref\n",
    "    xN = complex_to_real_plus_imag_3d(real_plus_imag_to_complex_3d(m)[idx,:,:])\n",
    "    print(xN.shape) # (2*N, RO, PE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c40420",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get the start time\n",
    "st = time.time()\n",
    "\n",
    "\n",
    "########################################################## Image selection\n",
    "# for loop size\n",
    "if opt==0:\n",
    "  L = N\n",
    "else:\n",
    "  L = 1\n",
    "  NInd = 0 # If '0' don't select an individual image\n",
    "\n",
    "for el in range(L):\n",
    "  if opt==0:\n",
    "    NInd = el+1 # pick one image from N images\n",
    "    Ns   = 4 # Number of channels common to all images\n",
    "    Nz   = 0 # Number of image specific channels\n",
    "    Nout = 1 # Number of outputs, 1 or N (2*Nout = output channels) \n",
    "    Nin = Nz+Ns\n",
    "  elif opt==1: # Fix noise stack in with image specific output channels\n",
    "    Ns   = 4 # Number of channels common to all images\n",
    "    Nz   = 0 # Number of image specific channels\n",
    "    Nout = N # Number of outputs, 1 or N (2*Nout = output channels)\n",
    "    Nin = Nz+Ns\n",
    "  elif opt==2: # [Ns; Nz] in with a single output channel\n",
    "    Ns   = 3 # Number of channels common to all images #<--3\n",
    "    Nz   = 1 # Number of image specific channels #<--1\n",
    "    Nout = 1 # Number of outputs, 1 or N (2*Nout = output channels)\n",
    "    Nin = Nz+Ns\n",
    "  elif opt==3: # [Ns; Nz] in with image specific output channels\n",
    "    Ns   = 3 # Number of channels common to all images\n",
    "    Nz   = 1 # Number of image specific channels\n",
    "    Nout = N # Number of outputs, 1 or N (2*Nout = output channels)\n",
    "    Nin = Nz+Ns\n",
    "  elif opt==4: # [Ns + Nz] in with a single output channel\n",
    "    Ns   = 1 # Number of channels common to all images \n",
    "    Nz   = Ns # Number of image specific channels\n",
    "    Nout = 1 # Number of outputs, 1 or N (2*Nout = output channels)\n",
    "    Nin = Nz\n",
    "  elif opt==5: # H[Nz] in with image-specific first layer and single output channel \n",
    "    Ns   = 0 # Number of channels common to all images\n",
    "    Nz   = 2 # Number of image specific channels\n",
    "    Nout = 1 # Number of outputs, 1 or N (2*Nout = output channels)\n",
    "    Nin = Nz*N\n",
    "  elif opt==6: # H[Nz] in with image-specific first layer and image specific output channels\n",
    "    Ns   = 0 # Number of channels common to all images\n",
    "    Nz   = 2 # Number of image specific channels\n",
    "    Nout = N # Number of outputs, 1 or N (2*Nout = output channels)\n",
    "    Nin = Nz*N\n",
    "\n",
    "\n",
    "  if NInd==0: # process all images\n",
    "    if FS:\n",
    "      x  = xN\n",
    "    # y  = yN\n",
    "    #     yn = ynN\n",
    "    yu = yuN\n",
    "    msk= mskN\n",
    "    S = SN\n",
    "  elif NInd > 0: # Process only one image\n",
    "    N  = 1\n",
    "    x  = xN[(NInd-1)*2:(NInd-1)*2+2]\n",
    "    y  = yN[(NInd-1)*2:(NInd-1)*2+2]\n",
    "    yn = ynN[(NInd-1)*2:(NInd-1)*2+2]\n",
    "    yu = yuN[(NInd-1)*2:(NInd-1)*2+2]\n",
    "    msk= mskN[(NInd-1):NInd]\n",
    "\n",
    "\n",
    "\n",
    "  ########################################################## Network setup\n",
    "  pad = 'reflection' # 'zero'\n",
    "  mse = torch.nn.MSELoss().type(dtype)\n",
    "  mae = torch.nn.L1Loss().type(dtype)\n",
    "\n",
    "  INPUT = 'noise' # 'noise', 'meshgrid', or 'hybrid'\n",
    "\n",
    "  # ra: note, setting num_channels_skip[0] = 0 may improve performance\n",
    "  if opt==5 or opt==6: \n",
    "    net = skip(Nin, 2*Nout, # skip|skip_depth6|skip_depth4|skip_depth2|UNET|ResNet\n",
    "    num_channels_down = [2]+[LSz]*(NLy-1), #[2, 128, 128, 128, 128, 128]\n",
    "    # num_channels_down[0] = 2,\n",
    "    num_channels_up =   [LSz]*NLy, #[128, 128, 128, 128, 128, 128]\n",
    "    num_channels_skip = [LSz]*NLy, #[128, 128, 128, 128, 128, 128] \n",
    "    filter_size_up   = [3]*NLy, #[3, 3, 3, 3, 3, 3], \n",
    "    filter_size_down = [3]*NLy, #[3, 3, 3, 3, 3, 3],\n",
    "    filter_skip_size = 1, # kernel size for the filters along the skip connections\n",
    "    upsample_mode='nearest', \n",
    "    output_act = 0, # 0 for none, 1 for sigmoid, 2 for tanh\n",
    "    need_bias=True, \n",
    "    pad=pad, \n",
    "    act_fun='LeakyReLU').type(dtype) # need_sigmoid forces the out to between 0 and 1\n",
    "  else:\n",
    "    # RA: The number of layers = 2^layers < image size\n",
    "    # Five layers for sl64 and six for other applications\n",
    "    net = skip(Nin, 2*Nout, # skip|skip_depth6|skip_depth4|skip_depth2|UNET|ResNet\n",
    "    num_channels_down = [LSz]*NLy, #[128, 128, 128, 128, 128]\n",
    "    num_channels_up =   [LSz]*NLy, #[128, 128, 128, 128, 128]\n",
    "    num_channels_skip =  [LSz]*NLy, # [LSz]*NLy, #[128, 128, 128, 128, 128]  \n",
    "    filter_size_up   = [3]*NLy, #[3, 3, 3, 3, 3], \n",
    "    filter_size_down = [3]*NLy, #[3, 3, 3, 3, 3],\n",
    "    filter_skip_size = 1, # kernel size for the filters along the skip connections\n",
    "    upsample_mode='nearest', \n",
    "    output_act = 0, # 0 for none, 1 for sigmoid, 2 for tanh\n",
    "    need_bias=True, \n",
    "    pad=pad, \n",
    "    act_fun='LeakyReLU', dropout=p).type(dtype) # need_sigmoid forces the out to between 0 and 1\n",
    "\n",
    "\n",
    "  s  = sum(np.prod(list(p.size())) for p in net.parameters())\n",
    "  print ('Number of params: %d' % s)\n",
    "\n",
    "\n",
    "  ########################################################## Setup network inputs\n",
    "  # generate network input\n",
    "  if FS:\n",
    "    x_tor   = np_to_torch(x).type(dtype)\n",
    "  yu_tor  = np_to_torch(yu).type(dtype)\n",
    "#   yn_tor  = np_to_torch(yn).type(dtype)\n",
    "  msk_tor = np_to_torch(msk).type(dtype)\n",
    "  # x_avg_tor = np_to_torch(x_avg).type(dtype)\n",
    "  S_tor = np_to_torch(S).type(dtype)\n",
    "\n",
    "#   print(yu_tor.size())\n",
    "#   print(msk_tor.size())\n",
    "#   print(S_tor.size())\n",
    "\n",
    "  net = net.type(dtype)\n",
    "  if opt==5 or opt==6:\n",
    "    # net = net.type(dtype)\n",
    "    z0 = torch.zeros(1,Nz,n[0],n[1]).type(dtype) # all zeros\n",
    "    z = get_noise(Nz, INPUT, x.shape[1:], var=1/10).type(dtype) - 1/20\n",
    "    z_saved = torch.clone(z)   # ra: use clone so that z and z_saved don't point to the same location\n",
    "    z0_saved = torch.clone(z0)\n",
    "    # zs = get_noise(Nin-Nz, INPUT, x.shape[1:], var=1./10).type(dtype) - 1/20\n",
    "    # zs_saved = torch.clone(zs)  # ra: use clone so that zs and zs_saved don't point to the same location\n",
    "\n",
    "  elif opt==4:\n",
    "    z = torch.zeros(1,Nz*N,n[0],n[1]).type(dtype) # all zeros\n",
    "    zs = get_noise(Ns, INPUT, x.shape[1:], var=1./10).type(dtype) - 1/20\n",
    "    z_saved  = torch.clone(z)\n",
    "    zs_saved = torch.clone(zs)\n",
    "    z0 = torch.zeros(1,Nz*N,n[0],n[1]).type(dtype) # all zeros\n",
    "    z0_saved = torch.clone(z0)\n",
    "\n",
    "  else: \n",
    "    zs = get_noise(Nin-Nz, INPUT, yu.shape[2:], var=1./10).type(dtype) - 1/20\n",
    "    zs_saved = torch.clone(zs)  # ra: use clone so that zs and zs_saved don't point to the same location\n",
    "    \n",
    "    z0 = get_noise(Nz, INPUT, yu.shape[2:], var=1./10).type(dtype) - 1/20\n",
    "    z = torch.zeros(1,Nz*N,n[0],n[1]).type(dtype) # all zeros\n",
    "    for i in range(N):\n",
    "      z[:,i*Nz:(i+1)*Nz,:,:] = z_scale * (0.8*z0 + 0.2*(get_noise(Nz, INPUT, yu.shape[2:], var=1./10).type(dtype) - 1/20))\n",
    "    z0 = torch.tile(z0,[1,N,1,1])\n",
    "    z_saved  = torch.clone(z)   # ra: use clone so that z and z_saved don't point to the same location\n",
    "    z0_saved = torch.clone(z0)\n",
    "\n",
    "  # print(z.shape)\n",
    "\n",
    "\n",
    "    \n",
    "  if nt==32:\n",
    "\n",
    "    if R==2:\n",
    "      LR = 1.5e-4 #1.5 4, 1.5 1 # 1 4, 1 1 # 7 5, 7 0 # 5 5, 7 0\n",
    "      z_lamb0 = 1.5e1\n",
    "    elif R==3:\n",
    "      LR = 1e-4 #1.5 4, 1.5 1 # 1 4, 1 1 # 7 5, 7 0 # 5 5, 7 0\n",
    "      z_lamb0 = 1e1\n",
    "    elif R==4:\n",
    "      LR = 7e-5 #1.5 4, 1.5 1 # 1 4, 1 1 # 7 5, 7 0 # 5 5, 7 0\n",
    "      z_lamb0 = 1.5e1\n",
    "    else: # both retrospective R=5 and prospective R=5.069307\n",
    "      LR = 5e-5 #1.5 4, 1.5 1 # 1 4, 1 1 # 7 5, 7 0 # 5 5, 7 0\n",
    "      z_lamb0 = 7e0\n",
    "  # else: # US case\n",
    "  elif nt==16:\n",
    "    if R==4:\n",
    "      LR=5e-5\n",
    "      z_lamb0=1.2e1\n",
    "\n",
    "\n",
    "\n",
    "  ########################################################## Main iterations\n",
    "  # from torch.nn.modules.loss import L1Loss\n",
    "  ii = 0\n",
    "  def closure():\n",
    "      global ii\n",
    "      # global running_loss\n",
    "      # global z_lamb\n",
    "      z_lamb = z_lamb0 #*(1 + 99 * ii/num_iter)\n",
    "      losses = torch.empty([N,1]).type(dtype)\n",
    "      xHat_tor = torch.empty(N,1,2*Nout, 1, n[0], n[1]).type(dtype)\n",
    "      reg_sig = reg_sig0*(1 - 0.9 * ii/num_iter)\n",
    "#       if ii<=num_iter/2:\n",
    "#         reg_sig = reg_sig0*0.9\n",
    "#       else:\n",
    "#         reg_sig = 0  \n",
    "     # reg_sig = reg_sig0 * (1 - ii/num_iter)\n",
    "\n",
    "\n",
    "\n",
    "      for i in range(N):\n",
    "        if opt==5 or opt==6:\n",
    "          xHat_tor[i,:,:,:,:] = net(torch.cat((torch.randn(1,Nz*i,n[0],n[1]).type(dtype) * reg_sig/(N**0.5), z + (torch.randn(1,Nz,n[0],n[1]).type(dtype) * reg_sig), torch.randn(1,N*Nz-Nz*(i+1),n[0],n[1]).type(dtype)* reg_sig/(N**0.5)), 1))\n",
    "        elif opt==4:\n",
    "          xHat_tor[i,:,:,:,:] = net(zs + z[:,i*Nz:(i+1)*Nz,:,:] + (torch.randn(1,Nz,n[0],n[1]).type(dtype) * reg_sig))\n",
    "        else: \n",
    "            ## opt = 2\n",
    "          xHat_tor[i,:,:,:,:,:] = torch.unsqueeze(net(torch.cat((zs + (torch.randn(1,Nin-Nz,n[0],n[1]).type(dtype) * reg_sig), z[:,i*Nz:(i+1)*Nz,:,:] + (torch.randn(1,Nz,n[0],n[1]).type(dtype) * reg_sig)), 1)), -3) #<-- change *1 to *4 AND <--zs to zs_saved\n",
    "          #xHat_tor[i,:,:,:,:,:] = torch.unsqueeze(net(torch.cat((zs, z[:,i*Nz:(i+1)*Nz,:,:] + (torch.randn(1,Nz,n[0],n[1]).type(dtype) * reg_sig)), 1)), -3) #<-- change *1 to *4 AND <--zs to zs_saved\n",
    "\n",
    "            # print(xHat_tor[i,:,:,:,:,:].size())\n",
    "\n",
    "          # xH = np.squeeze(torch_to_np(xHat_tor[i,:,:,:,:,:])) # (2, 160, 96)\n",
    "          # xHAbs = np.sqrt((xH[0,:,:])**2 + (xH[1,:,:])**2)\n",
    "          # plt.imshow(xHAbs, cmap=plt.cm.Greys_r)\n",
    "          # plt.show()\n",
    "          #print(xHat_tor.size())\n",
    "        if Nout==N:\n",
    "          xHatF_tor = fft2c_ra(xHat_tor[i,:,i*2:(i+1)*2,:,:], 'ortho')\n",
    "        elif Nout<N:\n",
    "            ## this case\n",
    "          xHatF_tor = fft2c_pra(multc(xHat_tor[i,:,:,:,:,:], S_tor), 'ortho')\n",
    "          # print(S_tor.size())\n",
    "          # print(xHatF_tor.size())\n",
    "\n",
    "          # xHF = torch_to_np(xHatF_tor) # (2, 8, 160, 96)\n",
    "          # xHFAbs = np.sqrt((xHF[0,:,:,:])**2 + (xHF[1,:,:,:])**2)\n",
    "          # fig = plt.figure(figsize=(16,5),facecolor='white', edgecolor=None)\n",
    "          # plt.imshow(np.reshape(np.transpose(xHFAbs,[1,0,2]), [n[0],n[1]*Nc]), cmap=plt.cm.Greys_r)\n",
    "          # plt.show()\n",
    "\n",
    "         \n",
    "\n",
    "    \n",
    "#         print(xHat_tor.size())\n",
    "#         print(xHatF_tor.size())\n",
    "        \n",
    "        losses[i] = mse(xHatF_tor*msk_tor[:,i:i+1,:,:,:],  yu_tor[:,i*2:(i+1)*2,:,:,:])\n",
    "        # print(msk_tor[:,i:i+1,:,:,:].size())\n",
    "        # print(yu_tor[:,i*2:(i+1)*2,:,:,:].size())\n",
    "        #losses[i] = mse(xHatF_tor,  yu_tor[:,i*2:(i+1)*2,:,:,:])\n",
    "        # yund = torch_to_np(yu_tor[:,i*2:(i+1)*2,:,:,:]) # (2, 8, 160, 96)\n",
    "        # yundAbs = np.sqrt((yund[0,:,:,:])**2 + (yund[1,:,:,:])**2)\n",
    "        # fig = plt.figure(figsize=(16,5),facecolor='white', edgecolor=None)\n",
    "        # plt.imshow(np.reshape(np.transpose(yundAbs,[1,0,2]), [n[0],n[1]*Nc]), cmap=plt.cm.Greys_r)\n",
    "        # plt.show()\n",
    "\n",
    "        \n",
    "      if opt==2 or opt==3 or opt==4:\n",
    "        z_loss = z_lamb * torch.mean(torch.sqrt(torch.mean(torch.abs(z)**2, axis=1)+1e-6)) # img spec.\n",
    "        # z_loss = z_lamb*mae(z, z0_saved) # z_loss = mse(z,z0_saved) #<--default\n",
    "        # z_loss = z_lamb*mae(z, torch.tile(z[:,0:Nz,:,:],[1,N,1,1]))\n",
    "        # z_loss = z_lamb*mae(z, torch.tile(z[:,np.remainder(ii,N)*Nz:(np.remainder(ii,N)+1)*Nz,:,:],[1,N,1,1]))\n",
    "      else:\n",
    "        z_loss = 0\n",
    "\n",
    "      total_loss = sum(losses) + z_loss\n",
    "\n",
    "      total_loss.backward()\n",
    "      running_loss[0,ii] = sum(losses) + z_loss/z_lamb\n",
    "    \n",
    "    \n",
    "      if FS:\n",
    "    ###\n",
    "        psn = np.zeros([N,1])\n",
    "\n",
    "        xHat = np.zeros((2*N,n[0],n[1]))\n",
    "        xHatS = np.zeros((2*N,n[0],n[1]))\n",
    "        xHatAbs = np.zeros((N,n[0],n[1]))\n",
    "        xAbs = np.zeros((N,n[0],n[1]))\n",
    "          \n",
    "        for i in range(N):\n",
    "          xHat[i*2:(i+1)*2,:,:] = np.squeeze(torch_to_np(xHat_tor[i,:,:,:,:,:]))\n",
    "          xHatS[i*2:(i+1)*2,:,:] = xHat[i*2:(i+1)*2,:,:] * sen_msk\n",
    "          xHatAbs[i:i+1,:,:] = np.sqrt((xHatS[i*2,:,:])**2 + (xHatS[i*2+1,:,:])**2)\n",
    "          xAbs[i:i+1,:,:] = np.sqrt((x[i*2,:,:])**2 + (x[i*2+1,:,:])**2)\n",
    "          \n",
    "          psn[i] = psnr(xAbs[i,:,:], xHatAbs[i,:,:], data_range = xHatAbs[i,:,:].max() - xHatAbs[i,:,:].min())\n",
    "          \n",
    "\n",
    "          \n",
    "        running_psn[0,ii] = np.mean(psn)\n",
    "    ###\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "      # print ('Iteration %05d    Loss %f' % (i, total_loss.item()), '\\r', end='')\n",
    "      if  PLOT and (ii ==0 or (ii+1) % show_every == 0):\n",
    "        if FS:\n",
    "          nmse = np.zeros([N,1])\n",
    "          ssm = np.zeros([N,1])\n",
    "          psn = np.zeros([N,1])\n",
    "          xAbs = np.zeros((N,n[0],n[1]))\n",
    "          errMap = np.zeros((2*N,n[0],n[1]))\n",
    "        \n",
    "        xHat = np.zeros((2*N,n[0],n[1]))\n",
    "        xHatS = np.zeros((2*N,n[0],n[1]))\n",
    "        xHatAbs = np.zeros((N,n[0],n[1]))\n",
    "\n",
    "\n",
    "        xHatF = np.zeros((2*N,n[0],n[1]))\n",
    "        xHatFAbs = np.zeros((N,n[0],n[1]))\n",
    "        yAbs = np.zeros((N,n[0],n[1]))\n",
    "        errFMap = np.zeros((N,n[0],n[1]))\n",
    "\n",
    "\n",
    "        for i in range(N):\n",
    "          if Nout==N:\n",
    "            xHat[i*2:(i+1)*2,:,:] = torch_to_np(xHat_tor[i, :, i*2:(i+1)*2,:,:,:])\n",
    "            xHatAbs[i:i+1,:,:] = np.sqrt((xHat[i*2,:,:])**2 + (xHat[i*2+1,:,:])**2)\n",
    "#             xAbs[i:i+1,:,:] = np.sqrt((x[i*2,:,:])**2 + (x[i*2+1,:,:])**2)\n",
    "          elif Nout<N:\n",
    "            # this case\n",
    "            xHat[i*2:(i+1)*2,:,:] = np.squeeze(torch_to_np(xHat_tor[i,:,:,:,:,:]))\n",
    "            xHatS[i*2:(i+1)*2,:,:] = xHat[i*2:(i+1)*2,:,:] * sen_msk\n",
    "            xHatAbs[i:i+1,:,:] = np.sqrt((xHatS[i*2,:,:])**2 + (xHatS[i*2+1,:,:])**2)\n",
    "            if FS:\n",
    "              xAbs[i:i+1,:,:] = np.sqrt((x[i*2,:,:])**2 + (x[i*2+1,:,:])**2)\n",
    "\n",
    "            # xHatF[i*2:(i+1)*2,:,:] = np.squeeze(torch_to_np(fft2c_pra(np_to_torch(np.expand_dims(xHatS[i*2:(i+1)*2,:,:], axis=1)),'ortho')))\n",
    "            # xHatFAbs[i:i+1,:,:] = np.sqrt((xHatF[i*2,:,:])**2 + (xHatF[i*2+1,:,:])**2)\n",
    "            # yAbs[i:i+1,:,:] = np.sqrt((y[i*2,:,:])**2 + (y[i*2+1,:,:])**2)\n",
    "          if FS:\n",
    "            nmse[i] =  np.mean((x[i*2:(i+1)*2,:,:]-xHatS[i*2:(i+1)*2,:,:])**2) / np.mean((x[i*2:(i+1)*2,:,:])**2)\n",
    "            ssm[i] = ssim(xHatAbs[i,:,:], xAbs[i,:,:], data_range = xHatAbs[i,:,:].max() - xHatAbs[i,:,:].min()) # xHatL1Abs[i:i+1,:,:].max() - xHatL1Abs[i:i+1,:,:].min() \n",
    "            psn[i] = psnr(xAbs[i,:,:], xHatAbs[i,:,:], data_range = xHatAbs[i,:,:].max() - xHatAbs[i,:,:].min())\n",
    "\n",
    "            errMap[i*2:(i+1)*2,:,:] = x[i*2:(i+1)*2,:,:]-xHatS[i*2:(i+1)*2,:,:]\n",
    "            # errFMap[i,:,:] = np.sqrt(np.sum(np.abs(y[i*2:(i+1)*2,:,:]-xHatF[i*2:(i+1)*2,:,:])**2, axis=0))\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        ## Printing and Plotting begins here...\n",
    "        print('Individual losses x 1e4: ',', '.join('%1.3f' % (losses[j]*1e4) for j in range(len(losses))))\n",
    "        print('Iteration: %1.3d,' %(ii+1), 'Loss x 1e4: %1.2f,' %(running_loss[0,ii]*1e4))\n",
    "        \n",
    "\n",
    "        \n",
    "        fig = plt.figure(figsize=(16,5),facecolor='white', edgecolor=None)\n",
    "        plt.imshow(np.reshape(np.transpose(xHat**g,[1,0,2]), [n[0],n[1]*2*N]), cmap=mps[0]) # use a specific color map\n",
    "        plt.title(\"xHat\")\n",
    "        plt.show()\n",
    "\n",
    "        if FS:\n",
    "          fig = plt.figure(figsize=(16,5),facecolor='white', edgecolor=None)\n",
    "          plt.imshow(np.reshape(np.transpose(errMap,[1,0,2]), [n[0],n[1]*2*N]), vmin=-0.1, vmax=0.1, cmap=plt.cm.Greys_r) # use a specific color map\n",
    "          plt.title(\"errxMap\")\n",
    "          plt.show()\n",
    "          print('Mean nmse: %1.2f,' %(10*np.log10(np.mean(nmse))), 'nmse: ',', '.join('%1.2f' % (10*np.log10(nmse[j])) for j in range(len(nmse)))) \n",
    "          print('Mean ssim: %1.3f,' %(np.mean(ssm)), 'ssim: ',', '.join('%1.3f' % (ssm[j]) for j in range(len(ssm)))) \n",
    "          print('Mean psnr: %1.3f,' %(np.mean(psn)), 'psnr: ',', '.join('%1.3f' % (psn[j]) for j in range(len(psn)))) \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # fig = plt.figure(figsize=(16,5),facecolor='white', edgecolor=None)\n",
    "        # plt.imshow(np.reshape(np.transpose(xHatFAbs**gm[1],[1,0,2]), [n[0],n[1]*N]), cmap=mps[1]) # use a specific color map\n",
    "        # plt.title(\"xHatFAbs\")\n",
    "        # plt.show()\n",
    "          \n",
    "        # fig = plt.figure(figsize=(16,5),facecolor='white', edgecolor=None)\n",
    "        # plt.imshow(np.reshape(np.transpose(yAbs**gm[1],[1,0,2]), [n[0],n[1]*N]), cmap=mps[1]) # use a specific color map\n",
    "        # plt.title(\"yAbs\")\n",
    "        # plt.show()\n",
    "          \n",
    "        # fig = plt.figure(figsize=(16,5),facecolor='white', edgecolor=None)\n",
    "        # plt.imshow(np.reshape(np.transpose(errFMap**gm[1],[1,0,2]), [n[0],n[1]*N]), cmap=plt.cm.Greys_r) # use a specific color map\n",
    "        # plt.title(\"errFMap\")\n",
    "        # plt.show() \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        fig = plt.figure(figsize=(16,5),facecolor='white', edgecolor=None)\n",
    "        if Nz == 0:\n",
    "          plt.imshow(np.reshape(np.transpose(np.concatenate((xAbs[0:1,:,:]**gm[0], xHatAbs[0:1,:,:]**gm[0]), axis=2),[1,0,2]), [n[0],n[1]*2]), vmin=0, vmax=0.7, cmap=plt.cm.Greys_r) # use a specific color map\n",
    "          plt.show() \n",
    "            \n",
    "        else: # opt=2\n",
    "          zNp = torch_to_np(z)\n",
    "          if FS:\n",
    "            plt.imshow(np.reshape(np.transpose(np.concatenate((xAbs[0:1,:,:]**gm[0], xHatAbs[0:1,:,:]**gm[0], 100*zNp[0:1,:,:]), axis=2),[1,0,2]), [n[0],n[1]*3]), cmap=plt.cm.Greys_r) # use a specific color map\n",
    "            plt.title(\"xAbs, xHatAbs, z (i=1)\")\n",
    "            plt.show()\n",
    "          else:\n",
    "            plt.imshow(np.reshape(np.transpose(np.concatenate((xHatAbs[0:1,:,:]**g, 10*zNp[0:1,:,:]), axis=2),[1,0,2]), [n[0],n[1]*2]), cmap=plt.cm.Greys_r) # use a specific color map\n",
    "            plt.title(\"xHatAbs, z (i=1)\")\n",
    "            plt.show()\n",
    "      ii += 1\n",
    "      return total_loss\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "  # num_iter = 15000 #12000\n",
    "  running_loss = torch.empty([1,num_iter]).type(dtype)\n",
    "  # reg_sig0 = 0.02 * (1 + (Np*1e3)**0.5) \n",
    "  if FS:\n",
    "    running_psn = torch.empty([1,num_iter]).type(dtype)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  print('=====optimizing over network and input=====')\n",
    "  OPT_OVER = 'net,input'\n",
    "  # z_lamb0 = 8*2e0 #<-- default: 5e1 for mse, 2e0 for mae, and 2e0 for group sparsity\n",
    "  # WtD = 0*1e-6 # weight decay\n",
    "  if Nz != 0 and Ns != 0:\n",
    "    p = get_params(OPT_OVER, net, ([z,zs])) #<-- ra: remove zs\n",
    "  if Nz != 0 and Ns == 0:\n",
    "    p = get_params(OPT_OVER, net, ([z])) #<-- ra: remove zs\n",
    "  if Ns != 0 and Nz == 0:\n",
    "    p = get_params(OPT_OVER, net, ([zs])) #<-- ra: remove zs\n",
    "  optimize('adam', p, closure, LR, num_iter, WtD)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  fig = plt.figure(figsize=(16,5),facecolor='white', edgecolor=None)\n",
    "  plt.plot(np.log10(torch_to_np(running_loss)))\n",
    "  plt.xlabel(\"No. of iterations\")\n",
    "  plt.ylabel(\"Total loss\")\n",
    "  plt.show()\n",
    "    \n",
    "  if FS:\n",
    "    fig = plt.figure(figsize=(16,5),facecolor='white', edgecolor=None)\n",
    "    plt.plot(torch_to_np(running_psn))\n",
    "    plt.xlabel(\"No. of iterations\")\n",
    "    plt.ylabel(\"PSNR\")\n",
    "    plt.show()\n",
    "    print(\"Max PSNR: \", np.max(torch_to_np(running_psn)), \"at Iteration: \", np.argmax(torch_to_np(running_psn)), \"/\", num_iter)\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "  ########################################################## Display and saving\n",
    "  xHat_tor = torch.empty(N,1,2*Nout, 1, n[0], n[1]).type(dtype)\n",
    "  for i in range(N):\n",
    "    if opt==5 or opt==6:\n",
    "      xHat_tor[i,:,:,:,:] = net(torch.cat((torch.zeros(1,Nz*i,n[0],n[1]).type(dtype), z , torch.zeros(1,N*Nz-Nz*(i+1),n[0],n[1]).type(dtype)), 1))\n",
    "    elif opt==4:\n",
    "      xHat_tor[i,:,:,:,:] = net(1*zs + 1*z[:,i*Nz:(i+1)*Nz,:,:])\n",
    "    else: \n",
    "        # this case\n",
    "      xHat_tor[i,:,:,:,:,:] = torch.unsqueeze(net(torch.cat((1*zs, 1*z[:,i*Nz:(i+1)*Nz,:,:]), 1)), -3)\n",
    "\n",
    "  if FS:\n",
    "    nmse = np.zeros([N,1])\n",
    "    ssm = np.zeros([N,1])\n",
    "    psn = np.zeros([N,1])\n",
    "    xAbs = np.zeros((N,n[0],n[1]))\n",
    "    errMap = np.zeros((N,n[0],n[1]))\n",
    "\n",
    "  xHat = np.zeros((2*N,n[0],n[1]))\n",
    "  xHatS = np.zeros((2*N,n[0],n[1]))\n",
    "  xHatAbs = np.zeros((N,n[0],n[1]))\n",
    "  xHatF = np.zeros((2*N,n[0],n[1]))\n",
    "  xHatFAbs = np.zeros((N,n[0],n[1]))\n",
    "  # yAbs = np.zeros((N,n[0],n[1]))\n",
    "  # errFMap = np.zeros((N,n[0],n[1]))\n",
    "\n",
    "  for i in range(N):\n",
    "    if Nout==N:\n",
    "      xHat[i*2:(i+1)*2,:,:] = torch_to_np(xHat_tor[i, :, i*2:(i+1)*2,:,:,:])\n",
    "      xHatAbs[i:i+1,:,:] = np.sqrt((xHat[i*2,:,:])**2 + (xHat[i*2+1,:,:])**2)\n",
    "      xHatF[i*2:(i+1)*2,:,:] = torch_to_np(fft2c_ra(xHat_tor[i, :, i*2:(i+1)*2,:,:,:],'ortho'))\n",
    "      xHatFAbs[i:i+1,:,:] = np.sqrt((xHatF[i*2,:,:])**2 + (xHatF[i*2+1,:,:])**2)\n",
    "      xAbs[i:i+1,:,:] = np.sqrt((x[i*2,:,:])**2 + (x[i*2+1,:,:])**2)\n",
    "    elif Nout<N:\n",
    "        ## this case\n",
    "      xHat[i*2:(i+1)*2,:,:] = np.squeeze(torch_to_np(xHat_tor[i,:,:,:,:,:]))\n",
    "      xHatS[i*2:(i+1)*2,:,:] = xHat[i*2:(i+1)*2,:,:] * sen_msk\n",
    "      xHatAbs[i:i+1,:,:] = np.sqrt((xHatS[i*2,:,:])**2 + (xHatS[i*2+1,:,:])**2)\n",
    "    \n",
    "      xHatF[i*2:(i+1)*2,:,:] = np.squeeze(torch_to_np(fft2c_pra(np_to_torch(np.expand_dims(xHatS[i*2:(i+1)*2,:,:], axis=1)),'ortho')))\n",
    "      xHatFAbs[i:i+1,:,:] = np.sqrt((xHatF[i*2,:,:])**2 + (xHatF[i*2+1,:,:])**2)\n",
    "      if FS:\n",
    "        xAbs[i:i+1,:,:] = np.sqrt((x[i*2,:,:])**2 + (x[i*2+1,:,:])**2)\n",
    "      # yAbs[i:i+1,:,:] = np.sqrt((y[i*2,:,:])**2 + (y[i*2+1,:,:])**2)\n",
    "\n",
    "    if FS:\n",
    "      nmse[i] =  np.mean((x[i*2:(i+1)*2,:,:]-xHatS[i*2:(i+1)*2,:,:])**2) / np.mean((x[i*2:(i+1)*2,:,:])**2)\n",
    "      ssm[i] = ssim(xHatAbs[i,:,:], xAbs[i,:,:], data_range = xHatAbs[i,:,:].max() - xHatAbs[i,:,:].min()) # xHatL1Abs[i:i+1,:,:].max() - xHatL1Abs[i:i+1,:,:].min()      \n",
    "      psn[i] = psnr(xAbs[i,:,:], xHatAbs[i,:,:], data_range = xHatAbs[i,:,:].max() - xHatAbs[i,:,:].min())\n",
    "\n",
    "      errMap[i,:,:] = np.sqrt(np.sum(np.abs(x[i*2:(i+1)*2,:,:]-xHatS[i*2:(i+1)*2,:,:])**2, axis=0))\n",
    "      # errFMap[i,:,:] = np.sqrt(np.sum(np.abs(y[i*2:(i+1)*2,:,:]-xHatF[i*2:(i+1)*2,:,:])**2, axis=0))\n",
    "    \n",
    "\n",
    "\n",
    "## printing and plotting after iterations:\n",
    "  if FS:\n",
    "    print('Mean nmse: %1.2f,' %(10*np.log10(np.mean(nmse))), 'nmse: ',', '.join('%1.2f' % (10*np.log10(nmse[j])) for j in range(len(nmse)))) \n",
    "    print('Mean ssim: %1.3f,' %(np.mean(ssm)), 'ssim: ',', '.join('%1.3f' % (ssm[j]) for j in range(len(ssm)))) \n",
    "    print('Mean psnr: %1.3f,' %(np.mean(psn)), 'psnr: ',', '.join('%1.3f' % (psn[j]) for j in range(len(psn)))) \n",
    "\n",
    "\n",
    "  # fig = plt.figure(figsize=(16,5),facecolor='white', edgecolor=None)\n",
    "  # plt.imshow(np.reshape(np.transpose(xHatFAbs**gm[1],[1,0,2]), [n[0],n[1]*N]), cmap=mps[1]) # use a specific color map\n",
    "  # plt.title(\"xHatFAbs\")\n",
    "  # plt.show()\n",
    "    \n",
    "  # fig = plt.figure(figsize=(16,5),facecolor='white', edgecolor=None)\n",
    "  # plt.imshow(np.reshape(np.transpose(yAbs**gm[1],[1,0,2]), [n[0],n[1]*N]), cmap=mps[1]) # use a specific color map\n",
    "  # plt.title(\"yAbs\")\n",
    "  # plt.show()\n",
    "    \n",
    "  # fig = plt.figure(figsize=(16,5),facecolor='white', edgecolor=None)\n",
    "  # plt.imshow(np.reshape(np.transpose(errFMap**gm[1],[1,0,2]), [n[0],n[1]*N]), cmap=plt.cm.Greys_r) # use a specific color map\n",
    "  # plt.title(\"errFMap\")\n",
    "  # plt.show() \n",
    "\n",
    "\n",
    "    \n",
    "    fig = plt.figure(figsize=(16,5),facecolor='white', edgecolor=None)\n",
    "    plt.imshow(np.reshape(np.transpose(xAbs**g,[1,0,2]), [n[0],n[1]*N]), cmap=mps[0]) # use a specific color map\n",
    "    plt.title(\"xAbs\")\n",
    "    plt.show()\n",
    "      \n",
    "    fig = plt.figure(figsize=(16,5),facecolor='white', edgecolor=None)\n",
    "    plt.imshow(np.reshape(np.transpose(errMap,[1,0,2]), [n[0],n[1]*N]), cmap=plt.cm.Greys_r) # use a specific color map\n",
    "    plt.title(\"errxMap\")\n",
    "    plt.show()\n",
    "\n",
    "  fig = plt.figure(figsize=(16,5),facecolor='white', edgecolor=None)\n",
    "  plt.imshow(np.reshape(np.transpose(xHatAbs**g,[1,0,2]), [n[0],n[1]*N]), cmap=mps[0]) # use a specific color map\n",
    "  plt.title(\"xHatAbs\")\n",
    "  plt.show()\n",
    "  # model = torch.load(data_path + 'model_'+'opt_%d_N_%d_Ind_%d' % (opt, N, NInd))\n",
    "  # model.eval()\n",
    "\n",
    "\n",
    "  ########################################################## Display/read the weights\n",
    "  # # Print model's state_dict\n",
    "  # print(\"Model's state_dict:\")\n",
    "  # for param_tensor in net.state_dict():\n",
    "  #     print(param_tensor, \"\\t\", net.state_dict()[param_tensor].size())\n",
    "\n",
    "  # # Print optimizer's state_dict\n",
    "  # print(\"Optimizer's state_dict:\")\n",
    "  # for var_name in optimizer.state_dict():\n",
    "  #     print(var_name, \"\\t\", optimizer.state_dict()[var_name])\n",
    "\n",
    "  # print(net) # this gives the structure of the network\n",
    "  L = 4 # read thie weights of this layer\n",
    "  i=0\n",
    "  for param in net.parameters():\n",
    "    wt = param.data\n",
    "    if i == L:\n",
    "      break\n",
    "    i=i+1\n",
    "\n",
    "  print(wt.shape)\n",
    "  print(wt.view(-1)) # this view(-1) reshpaes into a list\n",
    "  # print(zs.shape)\n",
    "\n",
    "\n",
    "  ########################################################## Display code vectors\n",
    "  if Ns !=0: # common z for all images (Ns = 3 for opt 2)\n",
    "    for i in range(Ns):\n",
    "        fig = plt.figure(figsize=(16,5),facecolor='white', edgecolor=None)\n",
    "        plt.imshow(np.concatenate((torch_to_np(zs_saved[:,i,:,:]), torch_to_np(zs[:,i,:,:]), torch_to_np(zs[:,i,:,:]-zs_saved[:,i,:,:])), axis=1), cmap=plt.cm.Greys_r) # use a specific color map\n",
    "        plt.title(\"Common Code Vector: \"+str(i+1)+\" (zs_init, zs, diff)\")\n",
    "        plt.show()\n",
    "        print(\"max diff. \",np.max(torch_to_np(zs[:,i,:,:]-zs_saved[:,i,:,:])))\n",
    "        \n",
    "        \n",
    "\n",
    "  if Nz !=0: # 1 z for each image (Nz = 1 for opt 2)\n",
    "    for i in range(N*Nz):\n",
    "      fig = plt.figure(figsize=(16,5),facecolor='white', edgecolor=None)\n",
    "      plt.imshow(np.concatenate((torch_to_np(z_saved[:,i,:,:]), torch_to_np(z[:,i,:,:]), torch_to_np(z[:,i,:,:]-z_saved[:,i,:,:])) , axis=1), cmap=plt.cm.Greys_r) # use a specific color map\n",
    "      plt.title(\"Image-Specific Code Vector: \"+str(i+1)+\" (z_init, z, diff)\")\n",
    "      plt.show()\n",
    "      print(\"min: \",torch.min(z[:,i,:,:]))\n",
    "      print(\"max: \",torch.max(z[:,i,:,:]))\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "# get the end time\n",
    "et = time.time()\n",
    "\n",
    "# get the execution time\n",
    "elapsed_time = et - st\n",
    "print('Execution time:', elapsed_time/60, 'minutes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414968b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FS=1\n",
    "i=0\n",
    "step=8\n",
    "gc = g\n",
    "if FS: \n",
    "    fig = plt.figure(figsize=(16,5),facecolor='white', edgecolor=None)\n",
    "    plt.imshow(np.reshape(np.transpose(xAbs[i::step]**gc,[1,0,2]), [n[0],n[1]*4]), cmap=mps[0]) # use a specific color map\n",
    "    plt.title(\"xAbs\")\n",
    "    plt.show()\n",
    "\n",
    "    fig = plt.figure(figsize=(16,5),facecolor='white', edgecolor=None)\n",
    "    plt.imshow(np.reshape(np.transpose(errMap[i::step],[1,0,2]), [n[0],n[1]*4]),vmin=0, vmax=np.max(errMap)/5, cmap=mps[0]) # use a specific color map\n",
    "    plt.title(\"ErrXMap\")\n",
    "    plt.show()\n",
    "\n",
    "fig = plt.figure(figsize=(16,5),facecolor='white', edgecolor=None)\n",
    "plt.imshow(np.reshape(np.transpose(xHatAbs[i::step]**gc,[1,0,2]), [n[0],n[1]*4]), cmap=mps[0]) # use a specific color map\n",
    "plt.title(\"xHatAbs\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa7d155",
   "metadata": {},
   "outputs": [],
   "source": [
    "sv=0\n",
    "# N=32\n",
    "cc=0\n",
    "if sv:\n",
    "    # save gif reference:\n",
    "    from utils.python_generate_gif import *\n",
    "\n",
    "    imgs = xHatAbs # recon magnitude images: xHatAbs = xHatAbs*sen_mask\n",
    "    # Example usage:\n",
    "    # Assuming you have a 3D NumPy array of image frames called 'frames' and you want to save the GIF as 'output.gif'\n",
    "    tmp_im = imgs/np.amax(imgs)*5 #scaling\n",
    "    tmp_im[tmp_im > 1] = 1 # clipping\n",
    "    tmp_im = (tmp_im * 255).astype(np.uint8)\n",
    "\n",
    "    if cc:\n",
    "        generate_gif(tmp_im, data_path_r + '/DISCUS_'+'N_%d_LR_%f_zlamb_%f' % (N, LR, z_lamb0) + '_R_%f'%R + '_with coil-correction.gif', 500)\n",
    "    else:\n",
    "        generate_gif(tmp_im, data_path_r + '/DISCUS_'+'N_%d_LR_%f_zlamb_%f' % (N, LR, z_lamb0) + '_R_%f'%R + '_without coil-correction.gif', 500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2838989",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sv=1\n",
    "if FS:\n",
    "  if sv==1: np.save(data_path_r + 'xRefDISCUS_'+'N_%d_LR_%f_zlamb_%f' % (N, LR, z_lamb0) + '_R_%f'%R + '.npy', x)\n",
    "  if sv==1: np.save(data_path_r + 'nmseDISCUS_'+'N_%d_LR_%f_zlamb_%f' % (N, LR, z_lamb0) + '_R_%f'%R + '.npy', nmse)\n",
    "  if sv==1: np.save(data_path_r + 'ssimDISCUS_'+'N_%d_LR_%f_zlamb_%f' % (N, LR, z_lamb0) + '_R_%f'%R + '.npy', ssm)\n",
    "  if sv==1: np.save(data_path_r + 'psnrDISCUS_'+'N_%d_LR_%f_zlamb_%f' % (N, LR, z_lamb0) + '_R_%f'%R + '.npy', psn)\n",
    "  if sv==1: np.save(data_path_r + 'PSNRtracking_DISCUS_'+'N_%d_LR_%f_zlamb_%f' % (N, LR, z_lamb0) + '_R_%f'%R + '.npy', torch_to_np(running_psn))\n",
    "\n",
    "if sv==1: np.save(data_path_r + 'xHatDISCUS_'+'N_%d_LR_%f_zlamb_%f' % (N, LR, z_lamb0) + '_R_%f'%R + '.npy', xHatS)\n",
    "\n",
    "if Nz!=0:\n",
    "  if sv==1: np.save(data_path_r + 'zDISCUS_'+'N_%d_LR_%f_zlamb_%f' % (N, LR, z_lamb0) + '_R_%f'%R + '.npy', torch_to_np(z))\n",
    "if Ns!=0: \n",
    "  if sv==1: np.save(data_path_r + 'zsDISCUS_'+'N_%d_LR_%f_zlamb_%f' % (N, LR, z_lamb0) + '_R_%f'%R + '.npy', torch_to_np(zs))\n",
    "\n",
    "if sv==1: np.save(data_path_r + 'LOSStracking_DISCUS_'+'N_%d_LR_%f_zlamb_%f' % (N, LR, z_lamb0) + '_R_%f'%R + '.npy', torch_to_np(running_loss))\n",
    "\n",
    "if sv==1: torch.save(net, data_path_r + 'model_DISCUS_'+'N_%d_LR_%f_zlamb_%f' % (N, LR, z_lamb0) + '_R_%f'%R )\n",
    "# if sv==1: torch.save(mlp, data_path + 'model_'+'opt_%d_N_%d_Ind_%d' % (opt, N, NInd))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b364e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(xHat.shape, xHat.dtype)\n",
    "xHat_c = xHat[0::2] + 1j*xHat[1::2]\n",
    "print(xHat_c.shape, xHat_c.dtype)\n",
    "\n",
    "ph = np.angle(xHat_c)\n",
    "plt.imshow(ph[10,:,:], cmap=mps[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DISCUS-Sultan",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "552489c190a5836f1d6d306c55383d234ab7e9c654141c6542f91293c67cd02a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
